{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import svm\n",
    "import xml.etree.ElementTree as ET\n",
    "from lxml import etree\n",
    "from scipy.sparse import hstack\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "\n",
    "path_train = r'E:\\Engineering\\8th sem\\nlp COMP 473\\NLP projects\\ABSA16_Laptops_Train_English_SB2.xml'\n",
    "path_test = r'E:\\Engineering\\8th sem\\nlp COMP 473\\NLP projects\\EN_LAPT_SB2_TEST.xml'\n",
    "\n",
    "#For stanford POS Tagger\n",
    "home = r'C:\\Users\\THe_strOX\\Anaconda3\\stanford-postagger-full-2017-06-09'\n",
    "from nltk.tag.stanford import StanfordPOSTagger as POS_Tag\n",
    "from nltk import word_tokenize\n",
    "_path_to_model = home + '/models/english-bidirectional-distsim.tagger' \n",
    "_path_to_jar = home + '/stanford-postagger.jar'\n",
    "stanford_tag = POS_Tag(model_filename=_path_to_model, path_to_jar=_path_to_jar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#xml parser\n",
    "def get_list(path):\n",
    "    tree=ET.parse(path)\n",
    "    root = tree.getroot()\n",
    "    text_list = []\n",
    "    opinion_list = []\n",
    "    for review in root.findall('Review'):\n",
    "        text_string=\"\"\n",
    "        opinion_inner_list=[]\n",
    "        for sent in review.findall('./sentences/sentence'):\n",
    "            text_string= text_string+ \" \"+ sent.find('text').text\n",
    "        text_list.append(text_string)\n",
    "        for opinion in review.findall('./Opinions/Opinion'):\n",
    "            opinion_dict = {\n",
    "                opinion.get('category').replace('#','_'): opinion.get('polarity')\n",
    "            }\n",
    "            opinion_inner_list.append(opinion_dict)\n",
    "        opinion_list.append(opinion_inner_list)\n",
    "    return text_list,opinion_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Selecting only 20 most common aspect.\n",
    "def get_most_common_aspect(opinion_list):\n",
    "    import nltk\n",
    "    opinion= []\n",
    "    for inner_list in opinion_list:\n",
    "        for _dict in inner_list:\n",
    "            for key in _dict:\n",
    "                opinion.append(key)\n",
    "    most_common_aspect = [k for k,v in nltk.FreqDist(opinion).most_common(20)]\n",
    "    return most_common_aspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#generate data frame\n",
    "def get_data_frame(text_list,opinion_list,most_common_aspect):\n",
    "    data={'Review':text_list}\n",
    "    df = pd.DataFrame(data)\n",
    "    if opinion_list:\n",
    "        for inner_list in opinion_list:\n",
    "            for _dict in inner_list:\n",
    "                for key in _dict:\n",
    "                    if key in most_common_aspect:\n",
    "                        df.loc[opinion_list.index(inner_list),key]=_dict[key]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#generate data frame for aspect extraction task\n",
    "def get_aspect_data_frame(df,most_common_aspect):\n",
    "    for common_aspect in most_common_aspect:\n",
    "        df[common_aspect]=df[common_aspect].replace(['positive','negative','neutral','conflict'],[1,1,1,1])\n",
    "    df = df.fillna(0)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_positive_data_frame(df,most_common_aspect):\n",
    "    for common_aspect in most_common_aspect:\n",
    "        df[common_aspect]=df[common_aspect].replace(['positive'],[1])\n",
    "        df[common_aspect]=df[common_aspect].replace(['negative','neutral','conflict'],[0,0,0])\n",
    "    df = df.fillna(0)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_negative_data_frame(df,most_common_aspect):\n",
    "    for common_aspect in most_common_aspect:\n",
    "        df[common_aspect]=df[common_aspect].replace(['negative'],[1])\n",
    "        df[common_aspect]=df[common_aspect].replace(['positive','neutral','conflict'],[0,0,0])\n",
    "    df = df.fillna(0)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_neutral_data_frame(df,most_common_aspect):\n",
    "    for common_aspect in most_common_aspect:\n",
    "        df[common_aspect]=df[common_aspect].replace(['neutral','conflict'],[1,1])\n",
    "        df[common_aspect]=df[common_aspect].replace(['negative','positive'],[0,0])\n",
    "    df = df.fillna(0)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#To tag using stanford pos tagger\n",
    "def posTag(review):\n",
    "    tagged_text_list=[]\n",
    "    for text in review:\n",
    "        tagged_text_list.append(stanford_tag.tag(word_tokenize(text)))\n",
    "    return tagged_text_list\n",
    "#posTag(\"this is random text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Filter the word with tag- noun,adjective,verb,adverb\n",
    "def filterTag(tagged_review):\n",
    "    final_text_list=[]\n",
    "    for text_list in tagged_review:\n",
    "        final_text=[]\n",
    "        for word,tag in text_list:\n",
    "            if tag in ['NN','NNS','NNP','NNPS','RB','RBR','RBS','JJ','JJR','JJS','VB','VBD','VBG','VBN','VBP','VBZ']:\n",
    "                final_text.append(word)\n",
    "        final_text_list.append(' '.join(final_text))\n",
    "    return final_text_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_dict_aspect(y,most_common_aspect):\n",
    "    position=[]\n",
    "    for innerlist in y:\n",
    "        position.append([i for i, j in enumerate(innerlist) if j == 1])\n",
    "    sorted_common=sorted(most_common_aspect)\n",
    "    dict_aspect=[]\n",
    "    for innerlist in position:\n",
    "        inner_dict={}\n",
    "        for word in sorted_common:\n",
    "            if sorted_common.index(word) in innerlist:\n",
    "                inner_dict[word]= 5\n",
    "            else:\n",
    "                inner_dict[word]=0\n",
    "        dict_aspect.append(inner_dict)\n",
    "    return dict_aspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Stage 1:\n",
    "#Making list to train\n",
    "train_text_list,train_opinion_list = get_list(path_train)\n",
    "most_common_aspect = get_most_common_aspect(train_opinion_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#This takes time to tag. Already tagged and saved. So, loading file ...\n",
    "#tagged_text_list_train=posTag(train_text_list)\n",
    "#joblib.dump(tagged_text_list_train, 'tagged_text_list_train.pkl')\n",
    "tagged_text_list_train=joblib.load('tagged_text_list_train.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#train list after filter\n",
    "final_train_text_list=filterTag(tagged_text_list_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#get data frame\n",
    "df_train = get_data_frame(final_train_text_list,train_opinion_list,most_common_aspect)\n",
    "df_train_aspect = get_aspect_data_frame(df_train,most_common_aspect)\n",
    "df_train_aspect = df_train_aspect.reindex_axis(sorted(df_train_aspect.columns), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Similar for test list\n",
    "test_text_list,test_opinion_list = get_list(path_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#tagged_text_list_test=posTag(test_text_list)\n",
    "#joblib.dump(tagged_text_list_test, 'tagged_text_list_test.pkl')\n",
    "tagged_text_list_test=joblib.load('tagged_text_list_test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_test_text_list=filterTag(tagged_text_list_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_test = get_data_frame(final_test_text_list,test_opinion_list,most_common_aspect)\n",
    "df_test_aspect = get_aspect_data_frame(df_test,most_common_aspect)\n",
    "df_test_aspect = df_test_aspect.reindex_axis(sorted(df_test_aspect.columns), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Sort the data frame according to aspect's name and separate data(X) and target(y)\n",
    "#df_train_aspect = df_train_aspect.sample(frac=1).reset_index(drop=True) #For randoming\n",
    "X_train= df_train_aspect.Review\n",
    "y_train = df_train_aspect.drop('Review',1)\n",
    "\n",
    "#df_test_aspect = df_test_aspect.sample(frac=1).reset_index(drop=True) #For randoming\n",
    "X_test = df_test_aspect.Review\n",
    "y_test = df_test_aspect.drop('Review',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Change y_train to numpy array\n",
    "import numpy as np\n",
    "y_train = np.asarray(y_train, dtype=np.int64)\n",
    "y_test = np.asarray(y_test, dtype=np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Generate word vecotors using CountVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk import word_tokenize          \n",
    "from nltk.stem import WordNetLemmatizer \n",
    "vect = CountVectorizer(max_df=1.0,stop_words='english')  \n",
    "X_train_dtm = vect.fit_transform(X_train)\n",
    "X_test_dtm = vect.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Create various models. These are multi-label models.\n",
    "nb_classif = OneVsRestClassifier(MultinomialNB()).fit(X_train_dtm, y_train)\n",
    "C = 1.0 #SVregularization parameter\n",
    "svc = OneVsRestClassifier(svm.SVC(kernel='linear', C=C)).fit(X_train_dtm, y_train)\n",
    "lin_svc = OneVsRestClassifier(svm.LinearSVC(C=C)).fit(X_train_dtm, y_train)\n",
    "sgd = OneVsRestClassifier(SGDClassifier()).fit(X_train_dtm,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Predict the test data using classifiers\n",
    "y_pred_class = nb_classif.predict(X_test_dtm)\n",
    "y_pred_class_svc = svc.predict(X_test_dtm)\n",
    "y_pred_class_lin_svc = lin_svc.predict(X_test_dtm)\n",
    "y_pred_class_sgd = sgd.predict(X_test_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Following code to test metrics of all aspect extraction classifiers\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.025\n",
      "0.05\n",
      "0.05\n",
      "0.0375\n"
     ]
    }
   ],
   "source": [
    "print(metrics.accuracy_score(y_test,y_pred_class))\n",
    "print(metrics.accuracy_score(y_test,y_pred_class_svc))\n",
    "print(metrics.accuracy_score(y_test,y_pred_class_lin_svc))\n",
    "print(metrics.accuracy_score(y_test,y_pred_class_sgd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75\n",
      "0.711229946524\n",
      "0.732193732194\n",
      "0.700657894737\n"
     ]
    }
   ],
   "source": [
    "print(metrics.precision_score(y_test,y_pred_class,average='micro'))\n",
    "print(metrics.precision_score(y_test,y_pred_class_svc,average='micro'))\n",
    "print(metrics.precision_score(y_test,y_pred_class_lin_svc,average='micro'))\n",
    "print(metrics.precision_score(y_test,y_pred_class_sgd,average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.457627118644\n",
      "0.64406779661\n",
      "0.622276029056\n",
      "0.515738498789\n"
     ]
    }
   ],
   "source": [
    "print(metrics.recall_score(y_test,y_pred_class,average='micro'))\n",
    "print(metrics.recall_score(y_test,y_pred_class_svc,average='micro'))\n",
    "print(metrics.recall_score(y_test,y_pred_class_lin_svc,average='micro'))\n",
    "print(metrics.recall_score(y_test,y_pred_class_sgd,average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.568421052632\n",
      "0.675984752224\n",
      "0.67277486911\n",
      "0.594142259414\n"
     ]
    }
   ],
   "source": [
    "print(metrics.f1_score(y_test,y_pred_class,average='micro'))\n",
    "print(metrics.f1_score(y_test,y_pred_class_svc,average='micro'))\n",
    "print(metrics.f1_score(y_test,y_pred_class_lin_svc,average='micro'))\n",
    "print(metrics.f1_score(y_test,y_pred_class_sgd,average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.14      0.24        14\n",
      "          1       0.71      0.50      0.59        24\n",
      "          2       0.00      0.00      0.00        12\n",
      "          3       0.00      0.00      0.00         4\n",
      "          4       0.00      0.00      0.00        21\n",
      "          5       0.00      0.00      0.00         8\n",
      "          6       0.00      0.00      0.00         7\n",
      "          7       0.76      0.64      0.69        39\n",
      "          8       1.00      1.00      1.00        80\n",
      "          9       0.44      0.17      0.24        24\n",
      "         10       0.62      0.70      0.65        46\n",
      "         11       0.00      0.00      0.00         5\n",
      "         12       0.57      0.30      0.39        27\n",
      "         13       0.57      0.45      0.50        29\n",
      "         14       0.77      0.33      0.47        30\n",
      "         15       0.00      0.00      0.00         4\n",
      "         16       0.00      0.00      0.00         9\n",
      "         17       0.00      0.00      0.00        15\n",
      "         18       0.00      0.00      0.00         4\n",
      "         19       0.60      0.27      0.37        11\n",
      "\n",
      "avg / total       0.57      0.46      0.49       413\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.78      1.00      0.88        14\n",
      "          1       0.68      0.71      0.69        24\n",
      "          2       0.86      0.50      0.63        12\n",
      "          3       0.12      0.25      0.17         4\n",
      "          4       0.56      0.43      0.49        21\n",
      "          5       0.75      0.38      0.50         8\n",
      "          6       0.20      0.14      0.17         7\n",
      "          7       0.74      0.67      0.70        39\n",
      "          8       1.00      0.97      0.99        80\n",
      "          9       0.63      0.50      0.56        24\n",
      "         10       0.68      0.74      0.71        46\n",
      "         11       0.33      0.40      0.36         5\n",
      "         12       0.83      0.74      0.78        27\n",
      "         13       0.56      0.66      0.60        29\n",
      "         14       0.60      0.40      0.48        30\n",
      "         15       0.67      0.50      0.57         4\n",
      "         16       0.18      0.22      0.20         9\n",
      "         17       0.80      0.27      0.40        15\n",
      "         18       1.00      0.25      0.40         4\n",
      "         19       0.60      0.27      0.37        11\n",
      "\n",
      "avg / total       0.72      0.64      0.67       413\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.78      1.00      0.88        14\n",
      "          1       0.65      0.71      0.68        24\n",
      "          2       1.00      0.42      0.59        12\n",
      "          3       0.17      0.25      0.20         4\n",
      "          4       0.64      0.43      0.51        21\n",
      "          5       1.00      0.25      0.40         8\n",
      "          6       0.33      0.14      0.20         7\n",
      "          7       0.74      0.67      0.70        39\n",
      "          8       1.00      0.96      0.98        80\n",
      "          9       0.61      0.46      0.52        24\n",
      "         10       0.70      0.72      0.71        46\n",
      "         11       0.25      0.20      0.22         5\n",
      "         12       0.83      0.74      0.78        27\n",
      "         13       0.54      0.66      0.59        29\n",
      "         14       0.61      0.37      0.46        30\n",
      "         15       1.00      0.25      0.40         4\n",
      "         16       0.20      0.22      0.21         9\n",
      "         17       1.00      0.20      0.33        15\n",
      "         18       1.00      0.25      0.40         4\n",
      "         19       0.75      0.27      0.40        11\n",
      "\n",
      "avg / total       0.75      0.62      0.66       413\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      0.64      0.69        14\n",
      "          1       0.60      0.75      0.67        24\n",
      "          2       0.00      0.00      0.00        12\n",
      "          3       0.00      0.00      0.00         4\n",
      "          4       0.50      0.19      0.28        21\n",
      "          5       0.00      0.00      0.00         8\n",
      "          6       0.00      0.00      0.00         7\n",
      "          7       0.63      0.62      0.62        39\n",
      "          8       1.00      0.99      0.99        80\n",
      "          9       0.67      0.33      0.44        24\n",
      "         10       0.65      0.61      0.63        46\n",
      "         11       0.29      0.40      0.33         5\n",
      "         12       0.71      0.37      0.49        27\n",
      "         13       0.58      0.48      0.53        29\n",
      "         14       0.71      0.33      0.45        30\n",
      "         15       0.00      0.00      0.00         4\n",
      "         16       0.20      0.11      0.14         9\n",
      "         17       0.67      0.13      0.22        15\n",
      "         18       0.33      0.25      0.29         4\n",
      "         19       0.43      0.27      0.33        11\n",
      "\n",
      "avg / total       0.64      0.52      0.55       413\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    print(metrics.classification_report(y_test, y_pred_class))\n",
    "    print(metrics.classification_report(y_test, y_pred_class_svc))\n",
    "    print(metrics.classification_report(y_test, y_pred_class_lin_svc))\n",
    "    print(metrics.classification_report(y_test, y_pred_class_sgd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Stage 2:\n",
    "#Generating extra feature that indicates which aspect category is present in the review\n",
    "train_dict_aspect=get_dict_aspect(y_train, most_common_aspect)\n",
    "d_train=DictVectorizer() \n",
    "X_train_aspect_dtm = d_train.fit_transform(train_dict_aspect)\n",
    "\n",
    "#y_test is used to generated extra feature in order to test the performance of 2nd classifer.\n",
    "#Use y_pred_class_svc(Highest performer for aspect classification) as input for extra feature to test the overall performace.\n",
    "test_dict_aspect=get_dict_aspect(y_test,most_common_aspect)\n",
    "d_test=DictVectorizer() \n",
    "X_test_aspect_dtm = d_test.fit_transform(test_dict_aspect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Function for classiflying positive,negative or neutral sentiment of all the aspects\n",
    "def classify_sentiment(df_train,df_test,X_train_aspect_dtm,X_test_aspect_dtm):\n",
    "    \n",
    "    df_train = df_train.reindex_axis(sorted(df_train_positive.columns), axis=1)\n",
    "    df_test = df_test.reindex_axis(sorted(df_test_positive.columns), axis=1)\n",
    "\n",
    "    import numpy as np\n",
    "    X_train = df_train.Review\n",
    "    y_train = df_train.drop('Review',1)\n",
    "    y_train = np.asarray(y_train, dtype=np.int64)\n",
    "\n",
    "    X_test = df_test.Review\n",
    "    y_test = df_test.drop('Review',1)\n",
    "    y_test = np.asarray(y_test, dtype=np.int64)\n",
    "\n",
    "    vect_sen = CountVectorizer(stop_words='english',ngram_range=(1,2))  \n",
    "    X_train_dtm = vect_sen.fit_transform(X_train)\n",
    "    X_test_dtm = vect_sen.transform(X_test)\n",
    "\n",
    "    #ombining word vector with extra feature.\n",
    "    from scipy.sparse import hstack\n",
    "    X_train_dtm=hstack((X_train_dtm, X_train_aspect_dtm))\n",
    "    X_test_dtm=hstack((X_test_dtm, X_test_aspect_dtm))\n",
    "\n",
    "    C = 1.0 #SVregularization parameter\n",
    "    nb_classif = OneVsRestClassifier(MultinomialNB()).fit(X_train_dtm, y_train)\n",
    "    svc = OneVsRestClassifier(svm.SVC(kernel='linear', C=C)).fit(X_train_dtm, y_train)\n",
    "    lin_svc = OneVsRestClassifier(svm.LinearSVC(C=C)).fit(X_train_dtm, y_train)\n",
    "    sgd = OneVsRestClassifier(SGDClassifier()).fit(X_train_dtm,y_train)\n",
    "\n",
    "    y_pred_class= nb_classif.predict(X_test_dtm)\n",
    "    y_pred_class_svc = svc.predict(X_test_dtm)\n",
    "    y_pred_class_lin_svc = lin_svc.predict(X_test_dtm)\n",
    "    y_pred_class_sgd = sgd.predict(X_test_dtm)\n",
    "    return (y_test,y_pred_class,y_pred_class_svc,y_pred_class_lin_svc,y_pred_class_sgd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_metrices(y_test,y_pred_class,y_pred_class_svc,y_pred_class_lin_svc,y_pred_class_sgd):\n",
    "    print(\"Accuracy:\")\n",
    "    print(metrics.accuracy_score(y_test,y_pred_class))\n",
    "    print(metrics.accuracy_score(y_test,y_pred_class_svc))\n",
    "    print(metrics.accuracy_score(y_test,y_pred_class_lin_svc))\n",
    "    print(metrics.accuracy_score(y_test,y_pred_class_sgd))\n",
    "\n",
    "    print(\"\\nAverage precision:\")\n",
    "    print(metrics.precision_score(y_test,y_pred_class,average='micro'))\n",
    "    print(metrics.precision_score(y_test,y_pred_class_svc,average='micro'))\n",
    "    print(metrics.precision_score(y_test,y_pred_class_lin_svc,average='micro'))\n",
    "    print(metrics.precision_score(y_test,y_pred_class_sgd,average='micro'))\n",
    "\n",
    "    print(\"\\nAverage recall:\")\n",
    "    print(metrics.recall_score(y_test,y_pred_class,average='micro'))\n",
    "    print(metrics.recall_score(y_test,y_pred_class_svc,average='micro'))\n",
    "    print(metrics.recall_score(y_test,y_pred_class_lin_svc,average='micro'))\n",
    "    print(metrics.recall_score(y_test,y_pred_class_sgd,average='micro'))\n",
    "    \n",
    "    print(\"\\nAverage f1:\")\n",
    "    print(metrics.f1_score(y_test,y_pred_class,average='micro'))\n",
    "    print(metrics.f1_score(y_test,y_pred_class_svc,average='micro'))\n",
    "    print(metrics.f1_score(y_test,y_pred_class_lin_svc,average='micro'))\n",
    "    print(metrics.f1_score(y_test,y_pred_class_sgd,average='micro'))\n",
    "\n",
    "    print(\"\\nClassification report:\")\n",
    "    print(metrics.classification_report(y_test, y_pred_class))\n",
    "    print(metrics.classification_report(y_test, y_pred_class_svc))\n",
    "    print(metrics.classification_report(y_test, y_pred_class_lin_svc))\n",
    "    print(metrics.classification_report(y_test, y_pred_class_sgd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      "0.15\n",
      "0.35\n",
      "0.3125\n",
      "0.125\n",
      "\n",
      "Average precision:\n",
      "0.857142857143\n",
      "0.745762711864\n",
      "0.756097560976\n",
      "0.704545454545\n",
      "\n",
      "Average recall:\n",
      "0.260869565217\n",
      "0.797101449275\n",
      "0.673913043478\n",
      "0.673913043478\n",
      "\n",
      "Average f1:\n",
      "0.4\n",
      "0.77057793345\n",
      "0.712643678161\n",
      "0.688888888889\n",
      "\n",
      "Classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        12\n",
      "          1       0.00      0.00      0.00        14\n",
      "          2       0.00      0.00      0.00         6\n",
      "          3       0.00      0.00      0.00         3\n",
      "          4       0.00      0.00      0.00        15\n",
      "          5       0.00      0.00      0.00         7\n",
      "          6       0.00      0.00      0.00         4\n",
      "          7       0.00      0.00      0.00        26\n",
      "          8       0.83      0.95      0.89        61\n",
      "          9       0.00      0.00      0.00        11\n",
      "         10       1.00      0.39      0.56        36\n",
      "         11       0.00      0.00      0.00         4\n",
      "         12       0.00      0.00      0.00        12\n",
      "         13       0.00      0.00      0.00        18\n",
      "         14       0.00      0.00      0.00        23\n",
      "         15       0.00      0.00      0.00         3\n",
      "         16       0.00      0.00      0.00         7\n",
      "         17       0.00      0.00      0.00         8\n",
      "         18       0.00      0.00      0.00         2\n",
      "         19       0.00      0.00      0.00         4\n",
      "\n",
      "avg / total       0.31      0.26      0.27       276\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.83      0.87        12\n",
      "          1       0.67      0.71      0.69        14\n",
      "          2       0.50      1.00      0.67         6\n",
      "          3       0.75      1.00      0.86         3\n",
      "          4       0.65      0.73      0.69        15\n",
      "          5       0.75      0.43      0.55         7\n",
      "          6       0.67      0.50      0.57         4\n",
      "          7       0.71      0.77      0.74        26\n",
      "          8       0.89      0.93      0.91        61\n",
      "          9       0.47      0.82      0.60        11\n",
      "         10       0.89      0.89      0.89        36\n",
      "         11       0.75      0.75      0.75         4\n",
      "         12       0.60      0.75      0.67        12\n",
      "         13       0.72      0.72      0.72        18\n",
      "         14       0.75      0.91      0.82        23\n",
      "         15       0.67      0.67      0.67         3\n",
      "         16       0.25      0.14      0.18         7\n",
      "         17       0.80      0.50      0.62         8\n",
      "         18       0.67      1.00      0.80         2\n",
      "         19       1.00      0.50      0.67         4\n",
      "\n",
      "avg / total       0.76      0.80      0.77       276\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.75      0.86        12\n",
      "          1       0.64      0.64      0.64        14\n",
      "          2       0.60      0.50      0.55         6\n",
      "          3       0.75      1.00      0.86         3\n",
      "          4       0.69      0.60      0.64        15\n",
      "          5       1.00      0.14      0.25         7\n",
      "          6       0.00      0.00      0.00         4\n",
      "          7       0.68      0.65      0.67        26\n",
      "          8       0.88      0.92      0.90        61\n",
      "          9       0.44      0.73      0.55        11\n",
      "         10       0.89      0.86      0.87        36\n",
      "         11       1.00      0.50      0.67         4\n",
      "         12       0.45      0.42      0.43        12\n",
      "         13       0.73      0.61      0.67        18\n",
      "         14       0.71      0.65      0.68        23\n",
      "         15       1.00      0.33      0.50         3\n",
      "         16       0.00      0.00      0.00         7\n",
      "         17       0.75      0.38      0.50         8\n",
      "         18       0.67      1.00      0.80         2\n",
      "         19       1.00      0.25      0.40         4\n",
      "\n",
      "avg / total       0.74      0.67      0.69       276\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.58      0.74        12\n",
      "          1       0.64      1.00      0.78        14\n",
      "          2       0.50      0.83      0.62         6\n",
      "          3       0.75      1.00      0.86         3\n",
      "          4       0.72      0.87      0.79        15\n",
      "          5       0.50      0.14      0.22         7\n",
      "          6       0.75      0.75      0.75         4\n",
      "          7       0.53      0.31      0.39        26\n",
      "          8       0.88      0.85      0.87        61\n",
      "          9       0.38      0.55      0.44        11\n",
      "         10       0.78      0.97      0.86        36\n",
      "         11       0.80      1.00      0.89         4\n",
      "         12       0.67      0.17      0.27        12\n",
      "         13       0.73      0.44      0.55        18\n",
      "         14       0.73      0.83      0.78        23\n",
      "         15       0.00      0.00      0.00         3\n",
      "         16       0.00      0.00      0.00         7\n",
      "         17       0.33      0.12      0.18         8\n",
      "         18       0.67      1.00      0.80         2\n",
      "         19       0.30      0.75      0.43         4\n",
      "\n",
      "avg / total       0.69      0.67      0.65       276\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#For positive sentiment classifier\n",
    "df_train = get_data_frame(final_train_text_list,train_opinion_list,most_common_aspect)\n",
    "df_test = get_data_frame(final_test_text_list,test_opinion_list,most_common_aspect)\n",
    "\n",
    "df_train_positive = get_positive_data_frame(df_train,most_common_aspect)\n",
    "df_test_positive = get_positive_data_frame(df_test,most_common_aspect)\n",
    "y_test_pos,y_pred_class_pos,y_pred_class_svc_pos,y_pred_class_lin_svc_pos,y_pred_class_sgd_pos=classify_sentiment(df_train_positive,df_test_positive,X_train_aspect_dtm,X_test_aspect_dtm)\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    print_metrices(y_test_pos,y_pred_class_pos,y_pred_class_svc_pos,y_pred_class_lin_svc_pos,y_pred_class_sgd_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      "0.4875\n",
      "0.4875\n",
      "0.4625\n",
      "0.3375\n",
      "\n",
      "Average precision:\n",
      "0.7\n",
      "0.625\n",
      "0.666666666667\n",
      "0.449438202247\n",
      "\n",
      "Average recall:\n",
      "0.0642201834862\n",
      "0.412844036697\n",
      "0.330275229358\n",
      "0.366972477064\n",
      "\n",
      "Average f1:\n",
      "0.117647058824\n",
      "0.497237569061\n",
      "0.441717791411\n",
      "0.40404040404\n",
      "\n",
      "Classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00         2\n",
      "          1       0.00      0.00      0.00        10\n",
      "          2       0.00      0.00      0.00         2\n",
      "          3       0.00      0.00      0.00         1\n",
      "          4       0.00      0.00      0.00         4\n",
      "          5       0.00      0.00      0.00         1\n",
      "          6       0.00      0.00      0.00         3\n",
      "          7       0.00      0.00      0.00         3\n",
      "          8       0.67      0.33      0.44        18\n",
      "          9       0.00      0.00      0.00         9\n",
      "         10       0.00      0.00      0.00        10\n",
      "         11       0.00      0.00      0.00         1\n",
      "         12       0.00      0.00      0.00        12\n",
      "         13       1.00      0.09      0.17        11\n",
      "         14       0.00      0.00      0.00         6\n",
      "         15       0.00      0.00      0.00         0\n",
      "         16       0.00      0.00      0.00         2\n",
      "         17       0.00      0.00      0.00         5\n",
      "         18       0.00      0.00      0.00         2\n",
      "         19       0.00      0.00      0.00         7\n",
      "\n",
      "avg / total       0.21      0.06      0.09       109\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.50      0.50      0.50         2\n",
      "          1       0.67      0.60      0.63        10\n",
      "          2       0.00      0.00      0.00         2\n",
      "          3       0.00      0.00      0.00         1\n",
      "          4       0.50      0.25      0.33         4\n",
      "          5       0.00      0.00      0.00         1\n",
      "          6       1.00      0.67      0.80         3\n",
      "          7       0.00      0.00      0.00         3\n",
      "          8       0.77      0.56      0.65        18\n",
      "          9       1.00      0.22      0.36         9\n",
      "         10       0.78      0.70      0.74        10\n",
      "         11       0.00      0.00      0.00         1\n",
      "         12       0.75      0.25      0.38        12\n",
      "         13       0.70      0.64      0.67        11\n",
      "         14       0.00      0.00      0.00         6\n",
      "         15       0.00      0.00      0.00         0\n",
      "         16       0.00      0.00      0.00         2\n",
      "         17       0.00      0.00      0.00         5\n",
      "         18       0.00      0.00      0.00         2\n",
      "         19       0.75      0.86      0.80         7\n",
      "\n",
      "avg / total       0.60      0.41      0.47       109\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.50      0.67         2\n",
      "          1       0.67      0.40      0.50        10\n",
      "          2       0.00      0.00      0.00         2\n",
      "          3       0.00      0.00      0.00         1\n",
      "          4       0.33      0.25      0.29         4\n",
      "          5       0.00      0.00      0.00         1\n",
      "          6       1.00      0.33      0.50         3\n",
      "          7       0.00      0.00      0.00         3\n",
      "          8       0.77      0.56      0.65        18\n",
      "          9       0.00      0.00      0.00         9\n",
      "         10       0.86      0.60      0.71        10\n",
      "         11       0.00      0.00      0.00         1\n",
      "         12       1.00      0.08      0.15        12\n",
      "         13       0.70      0.64      0.67        11\n",
      "         14       0.00      0.00      0.00         6\n",
      "         15       0.00      0.00      0.00         0\n",
      "         16       0.00      0.00      0.00         2\n",
      "         17       0.00      0.00      0.00         5\n",
      "         18       0.00      0.00      0.00         2\n",
      "         19       0.83      0.71      0.77         7\n",
      "\n",
      "avg / total       0.56      0.33      0.39       109\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.50      0.67         2\n",
      "          1       0.71      0.50      0.59        10\n",
      "          2       0.00      0.00      0.00         2\n",
      "          3       0.00      0.00      0.00         1\n",
      "          4       1.00      0.25      0.40         4\n",
      "          5       0.00      0.00      0.00         1\n",
      "          6       0.67      0.67      0.67         3\n",
      "          7       0.13      0.67      0.22         3\n",
      "          8       0.38      0.67      0.48        18\n",
      "          9       1.00      0.11      0.20         9\n",
      "         10       0.50      0.70      0.58        10\n",
      "         11       0.00      0.00      0.00         1\n",
      "         12       0.00      0.00      0.00        12\n",
      "         13       0.75      0.27      0.40        11\n",
      "         14       0.00      0.00      0.00         6\n",
      "         15       0.00      0.00      0.00         0\n",
      "         16       0.00      0.00      0.00         2\n",
      "         17       0.00      0.00      0.00         5\n",
      "         18       0.00      0.00      0.00         2\n",
      "         19       0.86      0.86      0.86         7\n",
      "\n",
      "avg / total       0.46      0.37      0.35       109\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#For negative sentiment classifier\n",
    "df_train = get_data_frame(final_train_text_list,train_opinion_list,most_common_aspect)\n",
    "df_test = get_data_frame(final_test_text_list,test_opinion_list,most_common_aspect)\n",
    "\n",
    "df_train_neg = get_negative_data_frame(df_train,most_common_aspect)\n",
    "df_test_neg = get_negative_data_frame(df_test,most_common_aspect)\n",
    "\n",
    "y_test_neg,y_pred_class_neg,y_pred_class_svc_neg,y_pred_class_lin_svc_neg,y_pred_class_sgd_neg=classify_sentiment(df_train_neg,df_test_neg,X_train_aspect_dtm,X_test_aspect_dtm)\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    print_metrices(y_test_neg,y_pred_class_neg,y_pred_class_svc_neg,y_pred_class_lin_svc_neg,y_pred_class_sgd_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      "0.7375\n",
      "0.725\n",
      "0.7375\n",
      "0.5875\n",
      "\n",
      "Average precision:\n",
      "0.0\n",
      "0.153846153846\n",
      "0.333333333333\n",
      "0.105263157895\n",
      "\n",
      "Average recall:\n",
      "0.0\n",
      "0.0714285714286\n",
      "0.0357142857143\n",
      "0.0714285714286\n",
      "\n",
      "Average f1:\n",
      "0.0\n",
      "0.0975609756098\n",
      "0.0645161290323\n",
      "0.0851063829787\n",
      "\n",
      "Classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00         0\n",
      "          1       0.00      0.00      0.00         0\n",
      "          2       0.00      0.00      0.00         4\n",
      "          3       0.00      0.00      0.00         0\n",
      "          4       0.00      0.00      0.00         2\n",
      "          5       0.00      0.00      0.00         0\n",
      "          6       0.00      0.00      0.00         0\n",
      "          7       0.00      0.00      0.00        10\n",
      "          8       0.00      0.00      0.00         1\n",
      "          9       0.00      0.00      0.00         4\n",
      "         10       0.00      0.00      0.00         0\n",
      "         11       0.00      0.00      0.00         0\n",
      "         12       0.00      0.00      0.00         3\n",
      "         13       0.00      0.00      0.00         0\n",
      "         14       0.00      0.00      0.00         1\n",
      "         15       0.00      0.00      0.00         1\n",
      "         16       0.00      0.00      0.00         0\n",
      "         17       0.00      0.00      0.00         2\n",
      "         18       0.00      0.00      0.00         0\n",
      "         19       0.00      0.00      0.00         0\n",
      "\n",
      "avg / total       0.00      0.00      0.00        28\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00         0\n",
      "          1       0.00      0.00      0.00         0\n",
      "          2       0.00      0.00      0.00         4\n",
      "          3       0.00      0.00      0.00         0\n",
      "          4       0.00      0.00      0.00         2\n",
      "          5       0.00      0.00      0.00         0\n",
      "          6       0.00      0.00      0.00         0\n",
      "          7       0.29      0.20      0.24        10\n",
      "          8       0.00      0.00      0.00         1\n",
      "          9       0.00      0.00      0.00         4\n",
      "         10       0.00      0.00      0.00         0\n",
      "         11       0.00      0.00      0.00         0\n",
      "         12       0.00      0.00      0.00         3\n",
      "         13       0.00      0.00      0.00         0\n",
      "         14       0.00      0.00      0.00         1\n",
      "         15       0.00      0.00      0.00         1\n",
      "         16       0.00      0.00      0.00         0\n",
      "         17       0.00      0.00      0.00         2\n",
      "         18       0.00      0.00      0.00         0\n",
      "         19       0.00      0.00      0.00         0\n",
      "\n",
      "avg / total       0.10      0.07      0.08        28\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00         0\n",
      "          1       0.00      0.00      0.00         0\n",
      "          2       0.00      0.00      0.00         4\n",
      "          3       0.00      0.00      0.00         0\n",
      "          4       0.00      0.00      0.00         2\n",
      "          5       0.00      0.00      0.00         0\n",
      "          6       0.00      0.00      0.00         0\n",
      "          7       0.33      0.10      0.15        10\n",
      "          8       0.00      0.00      0.00         1\n",
      "          9       0.00      0.00      0.00         4\n",
      "         10       0.00      0.00      0.00         0\n",
      "         11       0.00      0.00      0.00         0\n",
      "         12       0.00      0.00      0.00         3\n",
      "         13       0.00      0.00      0.00         0\n",
      "         14       0.00      0.00      0.00         1\n",
      "         15       0.00      0.00      0.00         1\n",
      "         16       0.00      0.00      0.00         0\n",
      "         17       0.00      0.00      0.00         2\n",
      "         18       0.00      0.00      0.00         0\n",
      "         19       0.00      0.00      0.00         0\n",
      "\n",
      "avg / total       0.12      0.04      0.05        28\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00         0\n",
      "          1       0.00      0.00      0.00         0\n",
      "          2       0.00      0.00      0.00         4\n",
      "          3       0.00      0.00      0.00         0\n",
      "          4       0.00      0.00      0.00         2\n",
      "          5       0.00      0.00      0.00         0\n",
      "          6       0.00      0.00      0.00         0\n",
      "          7       0.00      0.00      0.00        10\n",
      "          8       0.00      0.00      0.00         1\n",
      "          9       0.00      0.00      0.00         4\n",
      "         10       0.00      0.00      0.00         0\n",
      "         11       0.00      0.00      0.00         0\n",
      "         12       0.18      0.67      0.29         3\n",
      "         13       0.00      0.00      0.00         0\n",
      "         14       0.00      0.00      0.00         1\n",
      "         15       0.00      0.00      0.00         1\n",
      "         16       0.00      0.00      0.00         0\n",
      "         17       0.00      0.00      0.00         2\n",
      "         18       0.00      0.00      0.00         0\n",
      "         19       0.00      0.00      0.00         0\n",
      "\n",
      "avg / total       0.02      0.07      0.03        28\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#For neutral or conflict sentiment classifier\n",
    "df_train = get_data_frame(final_train_text_list,train_opinion_list,most_common_aspect)\n",
    "df_test = get_data_frame(final_test_text_list,test_opinion_list,most_common_aspect)\n",
    "\n",
    "df_train_neu = get_neutral_data_frame(df_train,most_common_aspect)\n",
    "df_test_neu = get_neutral_data_frame(df_test,most_common_aspect)\n",
    "\n",
    "y_test_neu,y_pred_class_neu,y_pred_class_svc_neu,y_pred_class_lin_svc_neu,y_pred_class_sgd_neu=classify_sentiment(df_train_neu,df_test_neu,X_train_aspect_dtm,X_test_aspect_dtm)\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    print_metrices(y_test_neu,y_pred_class_neu,y_pred_class_svc_neu,y_pred_class_lin_svc_neu,y_pred_class_sgd_neu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a laptop review:\n",
      "\n",
      "This is my first asus laptop. So far i am really enjoying this laptop. 512GB SSD is super fast. Battery life is also good and can last very long. I have no complain on screen quality too as display supports 4k videos. Maybe that is why it costs a lot. This is an expensive laptop and it's price is very high compared to other laptops of similar specs. So, if you have no trouble paying for this laptop, it is pretty good.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Aspect Based Sentiment analyis of user's input.\n",
    "user_input=input(\"Enter a laptop review:\\n\\n\")\n",
    "#Preprocessing and vectorizing\n",
    "tagged_user_input = posTag([user_input])\n",
    "filter_tagged_user_input = filterTag(tagged_user_input)\n",
    "\n",
    "user_input_series=pd.Series(filter_tagged_user_input)\n",
    "user_input_series_dtm=vect.transform(user_input_series)\n",
    "\n",
    "predict_aspect= svc.predict(user_input_series_dtm)\n",
    "extra_feature=get_dict_aspect(predict_aspect, most_common_aspect)\n",
    "extra_feature_dtm=DictVectorizer().fit_transform(extra_feature)\n",
    "predict_aspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predicting weather the dectected aspect is positive or not\n",
    "test_opinion_list=[]\n",
    "df_test = get_data_frame(filter_tagged_user_input,test_opinion_list,most_common_aspect)\n",
    "df_train = get_data_frame(final_train_text_list,train_opinion_list,most_common_aspect)\n",
    "\n",
    "df_train_positive = get_positive_data_frame(df_train,most_common_aspect)\n",
    "y_test_pos,y_pred_class_pos,y_pred_class_svc_pos,y_pred_class_lin_svc_pos,y_pred_class_sgd_pos=classify_sentiment(df_train_positive,df_test,X_train_aspect_dtm,extra_feature_dtm)\n",
    "\n",
    "y_pred_class_svc_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predicting weather the dectected aspect is negative or not\n",
    "test_opinion_list=[]\n",
    "df_test = get_data_frame(filter_tagged_user_input,test_opinion_list,most_common_aspect)\n",
    "df_train = get_data_frame(final_train_text_list,train_opinion_list,most_common_aspect)\n",
    "\n",
    "df_train_negative = get_negative_data_frame(df_train,most_common_aspect)\n",
    "y_test_neg,y_pred_class_neg,y_pred_class_svc_neg,y_pred_class_lin_svc_neg,y_pred_class_sgd_neg=classify_sentiment(df_train_negative,df_test,X_train_aspect_dtm,extra_feature_dtm)\n",
    "\n",
    "y_pred_class_svc_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predicting weather the dectected aspect is neutral or coflict or not\n",
    "test_opinion_list=[]\n",
    "df_test = get_data_frame(filter_tagged_user_input,test_opinion_list,most_common_aspect)\n",
    "df_train = get_data_frame(final_train_text_list,train_opinion_list,most_common_aspect)\n",
    "\n",
    "df_train_neutral = get_neutral_data_frame(df_train,most_common_aspect)\n",
    "y_test_neu,y_pred_class_neu,y_pred_class_svc_neu,y_pred_class_lin_svc_neu,y_pred_class_sgd_neu=classify_sentiment(df_train_neutral,df_test,X_train_aspect_dtm,extra_feature_dtm)\n",
    "\n",
    "y_pred_class_svc_neu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 3, 8, 10, 13]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Finding the aspect that is positive\n",
    "index_positive=[]\n",
    "for i, (a, b) in enumerate(zip(predict_aspect.tolist()[0], y_pred_class_svc_pos.tolist()[0])):\n",
    "    if a ==1 and b==1:\n",
    "        index_positive.append(i)\n",
    "index_positive         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Finding the aspect that is negative\n",
    "index_negative=[]\n",
    "for i, (a, b) in enumerate(zip(predict_aspect.tolist()[0], y_pred_class_svc_neg.tolist()[0])):\n",
    "    if a ==1 and b==1:\n",
    "        index_negative.append(i)\n",
    "index_negative         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[12]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Finding the aspect that is neutral\n",
    "index_neutral=[]\n",
    "for i, (a, b) in enumerate(zip(predict_aspect.tolist()[0], y_pred_class_svc_neu.tolist()[0])):\n",
    "    if a ==1 and b==1:\n",
    "        index_neutral.append(i)\n",
    "index_neutral         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if index_positive:\n",
    "    for index in index_positive:\n",
    "        output.append(sorted(most_common_aspect)[index]+\": positive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if index_negative:\n",
    "    for index in index_negative:\n",
    "        output.append(sorted(most_common_aspect)[index]+\": negative\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if index_neutral:\n",
    "    for index in index_neutral:\n",
    "        output.append(sorted(most_common_aspect)[index]+\": neutral or conflict\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BATTERY_OPERATION_PERFORMANCE: positive',\n",
       " 'DISPLAY_GENERAL: positive',\n",
       " 'LAPTOP_GENERAL: positive',\n",
       " 'LAPTOP_OPERATION_PERFORMANCE: positive',\n",
       " 'LAPTOP_QUALITY: positive',\n",
       " 'LAPTOP_PRICE: neutral or conflict']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Prediction of Aspect Based Sentiment Analaysis for user's input\n",
    "output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
